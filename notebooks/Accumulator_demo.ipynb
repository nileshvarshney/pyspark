{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd6b3261-0db1-4520-a648-ea0332aa7a43",
   "metadata": {},
   "source": [
    "## Accumulator Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49f303c6-f8a7-49bb-be32-e74345f0a1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/22 14:32:46 WARN SimpleFunctionRegistry: The function udf_handle_bad_record replaced a previously registered function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+---------+------------+\n",
      "|source|destination|shipments|shipment_int|\n",
      "+------+-----------+---------+------------+\n",
      "| India|      India|        5|           5|\n",
      "| India|      China|        7|           7|\n",
      "| China|      India|    three|        null|\n",
      "| China|      China|        6|           6|\n",
      "| Japan|      India|     Five|        null|\n",
      "+------+-----------+---------+------------+\n",
      "\n",
      "Bad Record Counts 2\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "def handle_bad_record(shipments: str) -> int:\n",
    "    s = None\n",
    "    try:\n",
    "        s = int(shipments)\n",
    "    except ValueError:\n",
    "        bad_rec.add(1)\n",
    "    return s\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession \\\n",
    "        .builder\\\n",
    "        .appName(\"accumulator_demo\")\\\n",
    "        .master(\"local[3]\")\\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    data_list = [(\"India\", \"India\", '5'),\n",
    "                 (\"India\", \"China\", '7'),\n",
    "                 (\"China\", \"India\", 'three'),\n",
    "                 (\"China\", \"China\", '6'),\n",
    "                 (\"Japan\", \"India\", 'Five'),\n",
    "    ]\n",
    "    df = spark.createDataFrame(data_list).toDF(\"source\",\"destination\",\"shipments\")\n",
    "    bad_rec = spark.sparkContext.accumulator(0)\n",
    "    \n",
    "    # register udf\n",
    "    spark.udf.register(\"udf_handle_bad_record\", handle_bad_record, IntegerType())\n",
    "    \n",
    "    df.withColumn(\"shipment_int\", expr(\"udf_handle_bad_record(shipments)\")).show()\n",
    "    \n",
    "    print(f\"Bad Record Counts {str(bad_rec.value)}\")\n",
    "    \n",
    "    spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6af7fd0-7685-4b93-bfcb-88144d1bdaae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
